{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fd32d7f8f780dc",
   "metadata": {},
   "source": [
    "# Çok Özellikli Lineer Regressyon\n",
    "Çok özellikli lieer regresyon tek özellikli lieer regresyonunn aksine hedef değeri etkileyen birden fazla etmenin bulunduğu durumlarda kullanılır ki gerçek hayat problemlerinin çoğu böyledir. Lineer regresyon algoritmamızda kullandığımız doğrusal fonksiyonumuzu hatırlayacak olursak;\n",
    "$$ f_{\\mathbf{w},b}(x^i)= wx^i+b $$\n",
    "şeklindedir. \n",
    "Burada $i$ ifadesi girdinin indexini ifade eder. Çok özellikli lineer regresyon için kullanacağımız doğrusal fonksiyonumuz a bakacak olursak;\n",
    "$$ f_{\\mathbf{w},b}(x^i)= \\sum(w_jx^i_j) + b $$\n",
    "şeklindedir. Burada $i$ ifadesi basit lineer regresyon algoritma kullandığımız gibi `girdi indexi` $j$ ifadesi `özellik indexi` ifade eder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0034cec241e7a20",
   "metadata": {},
   "source": [
    "Basit lineer regresyon algoritmamızda olduğu gibi bu ifadeleri ev satış fiyatı tahmini için kullanacağamız çok değişkenli lieer regresyon algoritmamızı anlayabilmek için eğitim veri seti üzerinde inceleyelim.\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | `35`           | 178           |   \n",
    "\n",
    "Bu veri setinde görmüş olduğunuz gibi evlerin fiyatları haricindeki ( Evlerin fiyatları bizim için hedef değerdir. $y$) her bir sütun bir özelliği ve her bir satır bir girdiyi iafde etmektedir. Yani $x^3_4$ = 35 olacaktır. ( Matematiksel olarak indek değerleri 1' den dizinin boyutu olan $n$' e kadar sıralanır fakat bilgisayar bilimlerinde index değeri 0' dan başlar ve $n - 1$' e kadar gider.)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c58a103df1a9faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:04.766733Z",
     "start_time": "2025-02-02T17:54:04.638734Z"
    }
   },
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "73e12fd53dac1cd2",
   "metadata": {},
   "source": [
    "`x_tarin` değişkeni matris formuna sahip bir vektördür ve bu matrisi bilgisayar bilimlerindeki notasyon gereğince indexlerini 0' dan başlatıp modelleyecek olursak;\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Burada notasyonu daha iyi kavratabilmek açısından;\n",
    "- $x^(i)$ ifadesinde bulunan $i$ her girdiye ait olan index değerini ifade eder.  $\\mathbf{x}^{(i)}$ $ = (x^{(i)}_0, x^{(i)}_1, \\cdots,x^{(i)}_{n-1})$\n",
    "- $x^(i)_j$ ifadesinde bulunan $j$ her bir özelliğe ait olan index değerini ifade eder. \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3fbb0da9b47f2a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:04.793215Z",
     "start_time": "2025-02-02T17:54:04.783903Z"
    }
   },
   "source": [
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (3, 4), X Type:<class 'numpy.ndarray'>)\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "y Shape: (3,), y Type:<class 'numpy.ndarray'>)\n",
      "[460 232 178]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "fc8b880c05e0c8e2",
   "metadata": {},
   "source": [
    "## Doğrusal Fonksiyonun Parametreleri\n",
    "Hatırlanacağı üzere doğrusal fonkiyonun parametrelri $w,b$'dir. Bu parametrelerin çok özellikli lineer regresyon algoritmasında ifade biçimi;\n",
    "$$ f_{\\mathbf{w}b} = \\sum(w_jx^i_j)+b = w_0x^{(0)}_{0} + w_1x^{(0)}_{1} + w_2x^{(0)}_{2} + ... + w_{n-1}x^{(0)}_{n-1}+ w_0x^{(1)}_{0} + w_1x^{(1)}_{1} + w_2x^{(1)}_{2} + ... +  w_{n-1}x^{(1)}_{n-1}+ ... + w_0x^{(m-1)}_{0} + w_1x^{(m-1)}_{1} + w_2x^{(m-1)}_{2} + ... +  w_{n-1}x^{(m-1)}_{n-1} + b$$\n",
    "şeklindedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808739df3253af7",
   "metadata": {},
   "source": [
    "Bu durumda görmüş olduğunuz gibi $w$' de $x$ gibi vektörel bir ifadedir. $w$ vektörel anlamda gösterimi;\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "şeklindedir.\n",
    "- Özellik sayısı kadar $w$ değeri bulunmaktadır. Bu da $w$ sayısının $X$ matrisinin sütun sayısına eşit olduğunu ifade etmektedir.\n",
    "- $b$ parametresi ise basit doğrusal regresyon algoritmasinda olduğu gibi vektörel değil skaler bir büyüklüktür.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ef74321e6d2e612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.002128Z",
     "start_time": "2025-02-02T17:54:04.996069Z"
    }
   },
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "88d5d5b7ac92fd75",
   "metadata": {},
   "source": [
    "## Vektörel Gösterim\n",
    "Bu bakımdan çok özellikli lineer regresyonda kullanacağımız doğrusal fonksiyonumuzu $x$ ve $w$ değerlerinin birer vektör olmaları dolayısıyla vektörel çarpım şeklinde ifade edecek olursak;\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b $$\n",
    "şeklinde gösterebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487718e4fc21772f",
   "metadata": {},
   "source": [
    "Çok özellikli lineer regresyon algoritmamızı kendi atadığımız $w$ ve $b$ parametrelerine göre hesaplamak için kullanacağımız kod dizisi;"
   ]
  },
  {
   "cell_type": "code",
   "id": "282482507b85454e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.071427Z",
     "start_time": "2025-02-02T17:54:05.053829Z"
    }
   },
   "source": [
    "def linearFunction(x,w,b):\n",
    "    f = 0\n",
    "    m = x.shape[0]\n",
    "    for i in range(m):\n",
    "        f += w * x[i] \n",
    "    f += b\n",
    "    return f\n",
    "\n",
    "def linearFunction2(X,w,b):\n",
    "    f = np.dot(X,w) +b\n",
    "    return f"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "af94cb7378431cf9",
   "metadata": {},
   "source": [
    "şeklindedir. Bu hesaplama işlemini vektörel olarak yapabilmek için;"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c8816afde500b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.182586Z",
     "start_time": "2025-02-02T17:54:05.164370Z"
    }
   },
   "source": [
    "f = linearFunction2(X_train,w_init,b_init)\n",
    "print(f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459.99999762 231.99999837 177.99999899]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "db53e47aa3bdd511",
   "metadata": {},
   "source": [
    "kodunu yazarız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fbd1360905c7c",
   "metadata": {},
   "source": [
    "## Çok Özellik için Maliyet Hesaplama\n",
    "Çok özellik için maliyet fonksiyonumuz;\n",
    "$J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 1}^{m} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 $$ \n",
    "şeklinde ifade edilir."
   ]
  },
  {
   "cell_type": "code",
   "id": "d128c1f0359dcd72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.242294Z",
     "start_time": "2025-02-02T17:54:05.230934Z"
    }
   },
   "source": [
    "def costFunction(X, y, w, b):\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b\n",
    "        cost += (f_wb_i - y[i]) ** 2\n",
    "    cost /= 2*m\n",
    "    return cost\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "81deca65883ef1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.290793Z",
     "start_time": "2025-02-02T17:54:05.282634Z"
    }
   },
   "source": [
    "cost = costFunction(X_train, y_train, w_init, b_init)\n",
    "print(f'Maliyet : {type(cost)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maliyet : <class 'numpy.float64'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "b69e9e6691a253de",
   "metadata": {},
   "source": [
    "## Çok özellik için Gradyan İnişi\n",
    "Çok özellik için gradyan inişi algoritmasının ifadesi;\n",
    "$$\\begin{align*} \\text{yakınsayana}&\\text{ kadar tekrarla:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "şeklindedir. Bu ifadelerin kendi içlerindeki çözümleri ise;\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \n",
    "\\end{align}\n",
    "$$\n",
    "şeklindedir. İfadeleri yeniden düznleyecek olursak;\n",
    "$$ w_j = w_j -  \\alpha\\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  $$\n",
    "$$ b = b -  \\alpha\\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) $$\n",
    "biçimini alacaklardır."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac550aa56a12db33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.358153Z",
     "start_time": "2025-02-02T17:54:05.348773Z"
    }
   },
   "source": [
    "def computeGradient(X, y, w, b):\n",
    "    m,n = X.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]\n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_dw, dj_db\n",
    "dj_dw, dj_db = computeGradient(X_train, y_train, w_init, b_init)\n",
    "print(dj_dw, dj_db)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.72623574e-03 -6.27197255e-06 -2.21745574e-06 -6.92403377e-05] -1.6739251122999121e-06\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9595562dc1064268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.934422Z",
     "start_time": "2025-02-02T17:54:05.417609Z"
    }
   },
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):  \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  \n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   \n",
    "        w = w - alpha * dj_dw              \n",
    "        b = b - alpha * dj_db               \n",
    "      \n",
    "       \n",
    "        if i<100000:      \n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "\n",
    "    return w, b, J_history \n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,costFunction, computeGradient, alpha, iterations)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;31mTypeError\u001B[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m     20\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5.0e-7\u001B[39m\n\u001B[1;32m---> 22\u001B[0m w_final, b_final, J_hist \u001B[38;5;241m=\u001B[39m gradient_descent(X_train, y_train, initial_w, initial_b,costFunction, computeGradient, alpha, iterations)\n",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m, in \u001B[0;36mgradient_descent\u001B[1;34m(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001B[0m\n\u001B[0;32m      4\u001B[0m b \u001B[38;5;241m=\u001B[39m b_in\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_iters):\n\u001B[1;32m----> 8\u001B[0m     dj_db,dj_dw \u001B[38;5;241m=\u001B[39m gradient_function(X, y, w, b)   \n\u001B[0;32m      9\u001B[0m     w \u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m-\u001B[39m alpha \u001B[38;5;241m*\u001B[39m dj_dw              \n\u001B[0;32m     10\u001B[0m     b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m-\u001B[39m alpha \u001B[38;5;241m*\u001B[39m dj_db               \n",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m, in \u001B[0;36mcomputeGradient\u001B[1;34m(X, y, w, b)\u001B[0m\n\u001B[0;32m      7\u001B[0m     err \u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39mdot(X[i], w) \u001B[38;5;241m+\u001B[39m b) \u001B[38;5;241m-\u001B[39m y[i]\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n):                         \n\u001B[1;32m----> 9\u001B[0m         dj_dw[j] \u001B[38;5;241m=\u001B[39m dj_dw[j] \u001B[38;5;241m+\u001B[39m err \u001B[38;5;241m*\u001B[39m X[i, j]    \n\u001B[0;32m     10\u001B[0m     dj_db \u001B[38;5;241m=\u001B[39m dj_db \u001B[38;5;241m+\u001B[39m err                        \n\u001B[0;32m     11\u001B[0m dj_dw \u001B[38;5;241m=\u001B[39m dj_dw \u001B[38;5;241m/\u001B[39m m                                \n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b186f1d3-3759-494b-9c23-c1833c83f131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.942196400Z",
     "start_time": "2025-02-02T17:42:07.692947Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      4\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5.0e-7\u001B[39m\n\u001B[1;32m----> 6\u001B[0m w_final, b_final, J_hist \u001B[38;5;241m=\u001B[39m gradient_descent(X_train, y_train, initial_w, initial_b,costFunction, computeGradient, alpha, iterations)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb,w found by gradient descent: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mb_final\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mw_final\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m m,_ \u001B[38;5;241m=\u001B[39m X_train\u001B[38;5;241m.\u001B[39mshape\n",
      "Cell \u001B[1;32mIn[9], line 18\u001B[0m, in \u001B[0;36mgradient_descent\u001B[1;34m(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001B[0m\n\u001B[0;32m     14\u001B[0m         J_history\u001B[38;5;241m.\u001B[39mappend(cost_function(X, y, w, b))\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i\u001B[38;5;241m%\u001B[39m math\u001B[38;5;241m.\u001B[39mceil(num_iters \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 18\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIteration \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m4d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Cost \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mfloat\u001B[39m(J_history[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m8.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m   \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m w, b, J_history\n",
      "\u001B[1;31mTypeError\u001B[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,costFunction, computeGradient, alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147a82ccfd80e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.943733800Z",
     "start_time": "2025-02-02T17:42:07.692947Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,costFunction, computeGradient, alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc47c258186e654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:05.975400200Z",
     "start_time": "2025-02-02T00:01:08.939114Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b59372f1197774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T17:54:06.027871Z",
     "start_time": "2025-02-02T00:01:08.986244Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
